{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paraqwel/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import logging\n",
    "logging.set_verbosity_error()\n",
    "from tqdm import tqdm\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from connectivity.effective import get_circuit_feature\n",
    "from evaluation.faithfulness import faithfulness as faithfulness_fn\n",
    "\n",
    "from data.buffer import unpack_batch\n",
    "\n",
    "from utils.ablation_fns import zero_ablation, mean_ablation, id_ablation\n",
    "from utils.savior import save_circuit\n",
    "from utils.plotting import plot_faithfulness\n",
    "from utils.metric_fns import metric_fn_logit, metric_fn_KL, metric_fn_statistical_distance, metric_fn_acc, metric_fn_MRR\n",
    "from utils.experiments_setup import load_model_and_modules, load_saes, get_architectural_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class single_input_buffer:\n",
    "    def __init__(self, model, batch_size, device, ctx_len=None, perm=None):\n",
    "        self.model = model\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "        self.ctx_len = ctx_len\n",
    "        self.data = {\n",
    "            \"clean\": [\"When Mary and John went to the store, John gave a glass to\"],\n",
    "            \"good\": [[\" Mary\"]],\n",
    "            \"corr\": [\"When Mary and John went to the store, Paul gave a glass to\"],\n",
    "            \"bad\": [[\" John\"]],\n",
    "        }\n",
    "        self.done = False\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.done:\n",
    "            raise StopIteration\n",
    "        self.done = True\n",
    "        tk = self.model.tokenizer\n",
    "        clean_tokens = tk(self.data[\"clean\"], return_tensors='pt', padding=True, return_attention_mask=False, return_token_type_ids=False)['input_ids'].to(self.device)\n",
    "        trg_idx = torch.zeros(clean_tokens.size(0), device=clean_tokens.device).long() - 1\n",
    "        trg = []\n",
    "        for i, good in enumerate(self.data[\"good\"]):\n",
    "            trg.append(tk(good, return_tensors='pt', return_attention_mask=False, return_token_type_ids=False)['input_ids'].to(self.device)[:, -1])\n",
    "        corr_tokens = tk(self.data[\"corr\"], return_tensors='pt', padding=True, return_attention_mask=False, return_token_type_ids=False)['input_ids'].to(self.device)\n",
    "        corr_trg = []\n",
    "        for i, bad in enumerate(self.data[\"bad\"]):\n",
    "            corr_trg.append(tk(bad, return_tensors='pt', return_attention_mask=False, return_token_type_ids=False)['input_ids'].to(self.device)[:, -1])\n",
    "\n",
    "        return {\n",
    "            \"clean\": clean_tokens,\n",
    "            \"trg_idx\": trg_idx,\n",
    "            \"trg\": trg,\n",
    "            \"corr\": corr_tokens,\n",
    "            \"corr_trg\": corr_trg,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model EleutherAI/pythia-70m-deduped into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model, name2mod = load_model_and_modules(device=DEVICE, resid=False)\n",
    "architectural_graph = get_architectural_graph(model, name2mod)\n",
    "print(architectural_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionaries = load_saes(model, name2mod, device=DEVICE)\n",
    "\n",
    "buffer = single_input_buffer(model, 1, DEVICE, ctx_len=None, perm=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embed': [], 'attn_0': ['embed'], 'mlp_0': ['embed'], 'y': ['mlp_4', 'attn_4', 'attn_3', 'attn_1', 'mlp_2', 'mlp_5', 'attn_0', 'embed', 'mlp_0', 'attn_2', 'attn_5', 'mlp_1', 'mlp_3'], 'attn_1': ['attn_0', 'embed', 'mlp_0'], 'mlp_1': ['attn_0', 'embed', 'mlp_0'], 'attn_2': ['attn_1', 'attn_0', 'embed', 'mlp_0', 'mlp_1'], 'mlp_2': ['attn_1', 'attn_0', 'embed', 'mlp_0', 'mlp_1'], 'attn_3': ['attn_1', 'attn_0', 'embed', 'mlp_0', 'attn_2', 'mlp_1', 'mlp_2'], 'mlp_3': ['attn_1', 'attn_0', 'embed', 'mlp_0', 'attn_2', 'mlp_1', 'mlp_2'], 'attn_4': ['attn_3', 'attn_1', 'mlp_2', 'attn_0', 'embed', 'mlp_0', 'attn_2', 'mlp_1', 'mlp_3'], 'mlp_4': ['attn_3', 'attn_1', 'mlp_2', 'attn_0', 'embed', 'mlp_0', 'attn_2', 'mlp_1', 'mlp_3'], 'attn_5': ['mlp_4', 'attn_4', 'attn_3', 'attn_1', 'mlp_2', 'attn_0', 'embed', 'mlp_0', 'attn_2', 'mlp_1', 'mlp_3'], 'mlp_5': ['mlp_4', 'attn_4', 'attn_3', 'attn_1', 'mlp_2', 'attn_0', 'embed', 'mlp_0', 'attn_2', 'mlp_1', 'mlp_3']}\n"
     ]
    }
   ],
   "source": [
    "for batch in tqdm(buffer):\n",
    "    tokens, trg_idx, trg, corr, corr_trg = unpack_batch(batch)\n",
    "\n",
    "    get_circuit_feature(\n",
    "            clean=tokens,\n",
    "            patch=corr,\n",
    "            model=model,\n",
    "            architectural_graph=architectural_graph,\n",
    "            name2mod=name2mod,\n",
    "            dictionaries=dictionaries,\n",
    "            metric_fn=metric_fn_logit,\n",
    "            metric_kwargs={\"trg_idx\": trg_idx, \"trg_pos\": trg, \"trg_neg\": corr_trg},\n",
    "            ablation_fn=zero_ablation,\n",
    "            edge_threshold=0.01,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(buffer)\n",
    "tokens, trg_idx, trg, corr, corr_trg = unpack_batch(batch)\n",
    "circuit = get_circuit_feature(\n",
    "    clean=tokens,\n",
    "    patch=corr,\n",
    "    model=model,\n",
    "    architectural_graph=architectural_graph,\n",
    "    name2mod=name2mod,\n",
    "    dictionaries=dictionaries,\n",
    "    metric_fn=metric_fn_logit,\n",
    "    metric_kwargs={\"trg_idx\": trg_idx, \"trg_pos\": trg, \"trg_neg\": corr_trg},\n",
    "    ablation_fn=zero_ablation,\n",
    "    edge_threshold=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = torch.logspace(0.1, 0, 10, 10).tolist()\n",
    "\n",
    "faithfulness = faithfulness_fn(\n",
    "    model,\n",
    "    submodules=submodules,\n",
    "    sae_dict=dictionaries,\n",
    "    name_dict=name_dict,\n",
    "    clean=tokens,\n",
    "    circuit=(tot_nodes, tot_edges),\n",
    "    thresholds=thresholds,\n",
    "    metric_fn=metric_fn_dict,\n",
    "    metric_fn_kwargs={\"trg_idx\": trg_idx, \"trg_pos\": trg, \"trg_neg\": corr_trg},\n",
    "    ablation_fn=ablation_fn,\n",
    "    patch=corr,\n",
    "    node_ablation=node_ablation,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
